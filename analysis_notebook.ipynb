{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# IMPORTS\n",
    "# --------------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# LOAD DATASET\n",
    "# --------------------------\n",
    "df = pd.read_csv('dropout.csv', delimiter=';')\n",
    "\n",
    "# --------------------------\n",
    "# DATA CLEANING\n",
    "# --------------------------\n",
    "# Check for missing values in the dataset and handle if necessary\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "df = df[df[\"Target\"] != 'Enrolled']\n",
    "# --------------------------\n",
    "# PREPROCESSING\n",
    "# --------------------------\n",
    "# Encoding the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['Target'] = label_encoder.fit_transform(df['Target'])\n",
    "\n",
    "# Splitting data into features and target\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# MODEL TRAINING & EVALUATION\n",
    "# --------------------------\n",
    "\n",
    "# Dictionary to store F1-scores for each model\n",
    "f1_scores = {\n",
    "    \"Dropout\": [],\n",
    "   # \"Enrolled\": [],\n",
    "    \"Graduate\": []\n",
    "}\n",
    "\n",
    "def print_neat_report(report_dict):\n",
    "    \"\"\"\n",
    "    Prints a neatly formatted classification report.\n",
    "    \n",
    "    Parameters:\n",
    "    - report_dict: Classification report in dictionary format.\n",
    "    \"\"\"\n",
    "    # Header\n",
    "    print(\"\\n{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"))\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Report for each class\n",
    "    for key, value in report_dict.items():\n",
    "        if key.isdigit():  # Only for the class entries, ignoring 'accuracy', 'macro avg', etc.\n",
    "            # class_name = \"Graduate\" if key == \"2\" else (\"Enrolled\" if key == \"1\" else \"Dropout\")\n",
    "            class_name = \"Graduate\" if key == \"1\" else \"Dropout\"\n",
    "            print(\"{:<20} {:<10.2f} {:<10.2f} {:<10.2f} {:<10}\".format(class_name, value['precision'], value['recall'], value['f1-score'], value['support']))\n",
    "    \n",
    "    # Overall metrics\n",
    "    print(\"\\n{:<20} {:<10} {:<10} {:<10} {:<10}\".format(\"Metric\", \"Precision\", \"Recall\", \"F1-score\", \"Support\"))\n",
    "    print(\"-\" * 60)\n",
    "    for key in ['macro avg', 'weighted avg']:\n",
    "        print(\"{:<20} {:<10.2f} {:<10.2f} {:<10.2f} {:<10}\".format(key, report_dict[key]['precision'], report_dict[key]['recall'], report_dict[key]['f1-score'], report_dict[key]['support']))\n",
    "    print(\"\\nAccuracy:\", report_dict['accuracy'])\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate_model(model, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Append F1-scores to the dictionary\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    f1_scores[\"Dropout\"].append(report['0']['f1-score'])\n",
    "    f1_scores[\"Graduate\"].append(report['1']['f1-score'])\n",
    "    #f1_scores[\"Graduate\"].append(report['2']['f1-score'])\n",
    "\n",
    "    print(\"\\n\\n-----\", model_name, \"-----\")\n",
    "    print_neat_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----- RANDOM FOREST -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.91       0.83       0.86       277.0     \n",
      "Graduate             0.90       0.95       0.92       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.90       0.89       0.89       726.0     \n",
      "weighted avg         0.90       0.90       0.90       726.0     \n",
      "\n",
      "Accuracy: 0.9008264462809917\n",
      "\n",
      "\n",
      "----- GRADIENT BOOSTING -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.90       0.83       0.86       277.0     \n",
      "Graduate             0.90       0.94       0.92       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.90       0.88       0.89       726.0     \n",
      "weighted avg         0.90       0.90       0.90       726.0     \n",
      "\n",
      "Accuracy: 0.8980716253443526\n",
      "\n",
      "\n",
      "----- SVM RBF KERNEL -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.94       0.80       0.87       277.0     \n",
      "Graduate             0.89       0.97       0.93       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.92       0.89       0.90       726.0     \n",
      "weighted avg         0.91       0.91       0.90       726.0     \n",
      "\n",
      "Accuracy: 0.90633608815427\n",
      "\n",
      "\n",
      "----- LOGISTIC REGRESSION -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.92       0.84       0.88       277.0     \n",
      "Graduate             0.91       0.95       0.93       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.91       0.90       0.90       726.0     \n",
      "weighted avg         0.91       0.91       0.91       726.0     \n",
      "\n",
      "Accuracy: 0.9104683195592287\n",
      "\n",
      "\n",
      "----- K-NEAREST NEIGHBORS -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.92       0.69       0.79       277.0     \n",
      "Graduate             0.83       0.96       0.89       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.88       0.82       0.84       726.0     \n",
      "weighted avg         0.86       0.86       0.85       726.0     \n",
      "\n",
      "Accuracy: 0.8567493112947658\n",
      "\n",
      "\n",
      "----- DECISION TREE -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.83       0.81       0.82       277.0     \n",
      "Graduate             0.88       0.90       0.89       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.85       0.85       0.85       726.0     \n",
      "weighted avg         0.86       0.86       0.86       726.0     \n",
      "\n",
      "Accuracy: 0.8608815426997245\n",
      "\n",
      "\n",
      "----- MULTI-LAYER PERCEPTRON -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.89       0.84       0.86       277.0     \n",
      "Graduate             0.90       0.93       0.92       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.90       0.89       0.89       726.0     \n",
      "weighted avg         0.90       0.90       0.90       726.0     \n",
      "\n",
      "Accuracy: 0.8980716253443526\n",
      "\n",
      "\n",
      "----- GAUSSIAN NAIVE BAYES -----\n",
      "\n",
      "Class                Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "Dropout              0.85       0.74       0.79       277.0     \n",
      "Graduate             0.85       0.92       0.88       449.0     \n",
      "\n",
      "Metric               Precision  Recall     F1-score   Support   \n",
      "------------------------------------------------------------\n",
      "macro avg            0.85       0.83       0.84       726.0     \n",
      "weighted avg         0.85       0.85       0.85       726.0     \n",
      "\n",
      "Accuracy: 0.849862258953168\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "train_and_evaluate_model(RandomForestClassifier(random_state=42), \"RANDOM FOREST\")\n",
    "train_and_evaluate_model(GradientBoostingClassifier(random_state=42), \"GRADIENT BOOSTING\")\n",
    "train_and_evaluate_model(SVC(kernel='rbf', random_state=42), \"SVM RBF KERNEL\")\n",
    "train_and_evaluate_model(LogisticRegression(max_iter=10000, random_state=42), \"LOGISTIC REGRESSION\")\n",
    "train_and_evaluate_model(KNeighborsClassifier(n_neighbors=5), \"K-NEAREST NEIGHBORS\")\n",
    "train_and_evaluate_model(DecisionTreeClassifier(random_state=42), \"DECISION TREE\")\n",
    "train_and_evaluate_model(MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42), \"MULTI-LAYER PERCEPTRON\")\n",
    "train_and_evaluate_model(GaussianNB(), \"GAUSSIAN NAIVE BAYES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Enrolled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m16\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(r1, f1_scores[\u001b[39m\"\u001b[39m\u001b[39mDropout\u001b[39m\u001b[39m\"\u001b[39m], width\u001b[39m=\u001b[39mbar_width, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgrey\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDropout\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(r2, f1_scores[\u001b[39m\"\u001b[39;49m\u001b[39mEnrolled\u001b[39;49m\u001b[39m\"\u001b[39;49m], width\u001b[39m=\u001b[39mbar_width, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgrey\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEnrolled\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(r3, f1_scores[\u001b[39m\"\u001b[39m\u001b[39mGraduate\u001b[39m\u001b[39m\"\u001b[39m], width\u001b[39m=\u001b[39mbar_width, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmagenta\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgrey\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraduate\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ben.nguyen/Documents/TDT4259-project/AppliedDS/analysis_notebook.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mComparison of F1-Scores Across Models\u001b[39m\u001b[39m'\u001b[39m, fontweight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbold\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Enrolled'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# --------------------------\n",
    "# COMPARISON VISUALIZATION   \n",
    "# --------------------------\n",
    "\n",
    "models = [\"Random Forest\", \"Gradient Boosting\", \"SVM RBF KERNEL\", \"Logistic Regression\", \"K-Nearest Neighbors\", \"Decision Tree\", \"Multi-Layer Perceptron\", \"Gaussian Naive Bayes\"]\n",
    "\n",
    "# Plotting F1-scores across models\n",
    "bar_width = 0.2\n",
    "r1 = range(len(models))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.bar(r1, f1_scores[\"Dropout\"], width=bar_width, color='blue', edgecolor='grey', label='Dropout')\n",
    "#plt.bar(r2, f1_scores[\"Enrolled\"], width=bar_width, color='green', edgecolor='grey', label='Enrolled')\n",
    "plt.bar(r3, f1_scores[\"Graduate\"], width=bar_width, color='magenta', edgecolor='grey', label='Graduate')\n",
    "plt.title('Comparison of F1-Scores Across Models', fontweight='bold')\n",
    "plt.xlabel('Models', fontweight='bold')\n",
    "plt.ylabel('F1-Score', fontweight='bold')\n",
    "plt.xticks([r + bar_width for r in range(len(models))], models, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
